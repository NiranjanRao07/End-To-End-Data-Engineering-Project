[2024-11-11T03:50:01.210+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-11T03:50:01.246+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T03:50:01.257+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T03:50:01.257+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 3
[2024-11-11T03:50:01.274+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): train_stock_model__1> on 2024-11-10 03:50:00+00:00
[2024-11-11T03:50:01.281+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=841) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-11-11T03:50:01.283+0000] {standard_task_runner.py:63} INFO - Started process 853 to run task
[2024-11-11T03:50:01.281+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'two_stocks_DAG', 'train_stock_model__1', 'scheduled__2024-11-10T03:50:00+00:00', '--job-id', '91', '--raw', '--subdir', 'DAGS_FOLDER/two_stocks.py', '--cfg-path', '/tmp/tmp64sx2bjz']
[2024-11-11T03:50:01.284+0000] {standard_task_runner.py:91} INFO - Job 91: Subtask train_stock_model__1
[2024-11-11T03:50:01.341+0000] {task_command.py:426} INFO - Running <TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [running]> on host e77131eeb98c
[2024-11-11T03:50:01.435+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='two_stocks_DAG' AIRFLOW_CTX_TASK_ID='train_stock_model__1' AIRFLOW_CTX_EXECUTION_DATE='2024-11-10T03:50:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-11-10T03:50:00+00:00'
[2024-11-11T03:50:01.436+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-11T03:50:01.446+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-11-11T03:50:01.447+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.0, Python Version: 3.12.3, Platform: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2024-11-11T03:50:01.448+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-11-11T03:50:01.815+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-11T03:50:01.816+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/two_stocks.py", line 85, in train_stock_model
    cur = return_snowflake_conn()
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/two_stocks.py", line 13, in return_snowflake_conn
    conn = hook.get_conn()
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 287, in get_conn
    conn = connector.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/__init__.py", line 55, in Connect
    return SnowflakeConnection(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 442, in __init__
    self.connect(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 745, in connect
    self.__open_connection()
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1073, in __open_connection
    self.authenticate_with_retry(self.auth_class)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1345, in authenticate_with_retry
    self._authenticate(auth_instance)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1373, in _authenticate
    auth.authenticate(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/auth/_auth.py", line 250, in authenticate
    ret = self._rest._post_request(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 734, in _post_request
    ret = self.fetch(
          ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 843, in fetch
    ret = self._request_exec_wrapper(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 979, in _request_exec_wrapper
    raise e
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 884, in _request_exec_wrapper
    return_object = self._request_exec(
                    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 1193, in _request_exec
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 1135, in _request_exec
    raise_failed_request_error(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 238, in raise_failed_request_error
    Error.errorhandler_wrapper(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 348, in hand_to_other_handler
    connection.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.InterfaceError: 250003 (08001): None: 404 Not Found: post https://azb69635.snowflakecomputing.com:443/session/v1/login-request?request_id=693cb331-9a04-43d3-a6cf-6d2c9b95ac91&databaseName=DEV&schemaName=&warehouse=COMPUTE_WH&roleName=&request_guid=7f16d51c-5058-4c32-907a-2e1c79843669
[2024-11-11T03:50:01.830+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=two_stocks_DAG, task_id=train_stock_model__1, run_id=scheduled__2024-11-10T03:50:00+00:00, execution_date=20241110T035000, start_date=20241111T035001, end_date=20241111T035001
[2024-11-11T03:50:01.842+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 91 for task train_stock_model__1 (250003 (08001): None: 404 Not Found: post https://azb69635.snowflakecomputing.com:443/session/v1/login-request?request_id=693cb331-9a04-43d3-a6cf-6d2c9b95ac91&databaseName=DEV&schemaName=&warehouse=COMPUTE_WH&roleName=&request_guid=7f16d51c-5058-4c32-907a-2e1c79843669; 853)
[2024-11-11T03:50:01.858+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-11-11T03:50:01.868+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-11-11T03:56:17.047+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-11T03:56:17.120+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T03:56:17.148+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T03:56:17.151+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 3
[2024-11-11T03:56:17.176+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): train_stock_model__1> on 2024-11-10 03:50:00+00:00
[2024-11-11T03:56:17.190+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=1039) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-11-11T03:56:17.193+0000] {standard_task_runner.py:63} INFO - Started process 1071 to run task
[2024-11-11T03:56:17.189+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'two_stocks_DAG', 'train_stock_model__1', 'scheduled__2024-11-10T03:50:00+00:00', '--job-id', '111', '--raw', '--subdir', 'DAGS_FOLDER/two_stocks.py', '--cfg-path', '/tmp/tmpz9hw9k3y']
[2024-11-11T03:56:17.196+0000] {standard_task_runner.py:91} INFO - Job 111: Subtask train_stock_model__1
[2024-11-11T03:56:17.290+0000] {task_command.py:426} INFO - Running <TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [running]> on host e77131eeb98c
[2024-11-11T03:56:17.452+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='two_stocks_DAG' AIRFLOW_CTX_TASK_ID='train_stock_model__1' AIRFLOW_CTX_EXECUTION_DATE='2024-11-10T03:50:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-11-10T03:50:00+00:00'
[2024-11-11T03:56:17.455+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-11T03:56:17.471+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-11-11T03:56:17.476+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.0, Python Version: 3.12.3, Platform: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2024-11-11T03:56:17.478+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-11-11T03:56:17.862+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-11T03:56:17.863+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/two_stocks.py", line 85, in train_stock_model
    cur = return_snowflake_conn()
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/two_stocks.py", line 13, in return_snowflake_conn
    conn = hook.get_conn()
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 287, in get_conn
    conn = connector.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/__init__.py", line 55, in Connect
    return SnowflakeConnection(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 442, in __init__
    self.connect(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 745, in connect
    self.__open_connection()
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1073, in __open_connection
    self.authenticate_with_retry(self.auth_class)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1345, in authenticate_with_retry
    self._authenticate(auth_instance)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1373, in _authenticate
    auth.authenticate(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/auth/_auth.py", line 250, in authenticate
    ret = self._rest._post_request(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 734, in _post_request
    ret = self.fetch(
          ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 843, in fetch
    ret = self._request_exec_wrapper(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 979, in _request_exec_wrapper
    raise e
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 884, in _request_exec_wrapper
    return_object = self._request_exec(
                    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 1193, in _request_exec
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 1135, in _request_exec
    raise_failed_request_error(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 238, in raise_failed_request_error
    Error.errorhandler_wrapper(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 348, in hand_to_other_handler
    connection.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.InterfaceError: 250003 (08001): None: 404 Not Found: post https://azb69635.snowflakecomputing.com:443/session/v1/login-request?request_id=6252968d-6e05-440f-af46-678e41236444&databaseName=DEV&schemaName=&warehouse=COMPUTE_WH&roleName=&request_guid=a3343710-1bec-4208-9a53-cfb96030c075
[2024-11-11T03:56:17.879+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=two_stocks_DAG, task_id=train_stock_model__1, run_id=scheduled__2024-11-10T03:50:00+00:00, execution_date=20241110T035000, start_date=20241111T035617, end_date=20241111T035617
[2024-11-11T03:56:17.897+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 111 for task train_stock_model__1 (250003 (08001): None: 404 Not Found: post https://azb69635.snowflakecomputing.com:443/session/v1/login-request?request_id=6252968d-6e05-440f-af46-678e41236444&databaseName=DEV&schemaName=&warehouse=COMPUTE_WH&roleName=&request_guid=a3343710-1bec-4208-9a53-cfb96030c075; 1071)
[2024-11-11T03:56:17.935+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-11-11T03:56:17.966+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-11-11T03:56:17.971+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-11-11T21:07:51.910+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-11T21:07:51.971+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T21:07:51.986+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T21:07:51.987+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 3
[2024-11-11T21:07:52.010+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): train_stock_model__1> on 2024-11-10 03:50:00+00:00
[2024-11-11T21:07:52.018+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=402) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-11-11T21:07:52.021+0000] {standard_task_runner.py:63} INFO - Started process 408 to run task
[2024-11-11T21:07:52.021+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'two_stocks_DAG', 'train_stock_model__1', 'scheduled__2024-11-10T03:50:00+00:00', '--job-id', '174', '--raw', '--subdir', 'DAGS_FOLDER/two_stocks.py', '--cfg-path', '/tmp/tmp6jmd6v2x']
[2024-11-11T21:07:52.023+0000] {standard_task_runner.py:91} INFO - Job 174: Subtask train_stock_model__1
[2024-11-11T21:07:52.438+0000] {task_command.py:426} INFO - Running <TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [running]> on host 889c1536fdc4
[2024-11-11T21:07:55.507+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='two_stocks_DAG' AIRFLOW_CTX_TASK_ID='train_stock_model__1' AIRFLOW_CTX_EXECUTION_DATE='2024-11-10T03:50:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-11-10T03:50:00+00:00'
[2024-11-11T21:07:55.638+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-11T21:07:55.661+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-11-11T21:07:55.663+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.0, Python Version: 3.12.3, Platform: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2024-11-11T21:07:55.665+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-11-11T21:07:56.021+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-11T21:07:56.021+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/two_stocks.py", line 85, in train_stock_model
    cur = return_snowflake_conn()
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/two_stocks.py", line 13, in return_snowflake_conn
    conn = hook.get_conn()
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 287, in get_conn
    conn = connector.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/__init__.py", line 55, in Connect
    return SnowflakeConnection(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 442, in __init__
    self.connect(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 745, in connect
    self.__open_connection()
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1073, in __open_connection
    self.authenticate_with_retry(self.auth_class)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1345, in authenticate_with_retry
    self._authenticate(auth_instance)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1373, in _authenticate
    auth.authenticate(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/auth/_auth.py", line 250, in authenticate
    ret = self._rest._post_request(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 734, in _post_request
    ret = self.fetch(
          ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 843, in fetch
    ret = self._request_exec_wrapper(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 979, in _request_exec_wrapper
    raise e
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 884, in _request_exec_wrapper
    return_object = self._request_exec(
                    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 1193, in _request_exec
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 1135, in _request_exec
    raise_failed_request_error(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 238, in raise_failed_request_error
    Error.errorhandler_wrapper(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 348, in hand_to_other_handler
    connection.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.InterfaceError: 250003 (08001): None: 404 Not Found: post https://azb69635.snowflakecomputing.com:443/session/v1/login-request?request_id=38c8de0e-fa70-43f4-9a4d-870ebda8b45c&databaseName=DEV&schemaName=&warehouse=COMPUTE_WH&roleName=&request_guid=8f0b32fc-d655-4b23-b251-913735a8de79
[2024-11-11T21:07:56.031+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=two_stocks_DAG, task_id=train_stock_model__1, run_id=scheduled__2024-11-10T03:50:00+00:00, execution_date=20241110T035000, start_date=20241111T210751, end_date=20241111T210756
[2024-11-11T21:07:56.046+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 174 for task train_stock_model__1 (250003 (08001): None: 404 Not Found: post https://azb69635.snowflakecomputing.com:443/session/v1/login-request?request_id=38c8de0e-fa70-43f4-9a4d-870ebda8b45c&databaseName=DEV&schemaName=&warehouse=COMPUTE_WH&roleName=&request_guid=8f0b32fc-d655-4b23-b251-913735a8de79; 408)
[2024-11-11T21:07:56.089+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-11-11T21:07:56.113+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-11-11T21:07:56.116+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-11-11T21:10:22.472+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-11T21:10:22.496+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T21:10:22.503+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T21:10:22.504+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 3
[2024-11-11T21:10:22.519+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): train_stock_model__1> on 2024-11-10 03:50:00+00:00
[2024-11-11T21:10:22.525+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=478) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-11-11T21:10:22.527+0000] {standard_task_runner.py:63} INFO - Started process 488 to run task
[2024-11-11T21:10:22.527+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'two_stocks_DAG', 'train_stock_model__1', 'scheduled__2024-11-10T03:50:00+00:00', '--job-id', '191', '--raw', '--subdir', 'DAGS_FOLDER/two_stocks.py', '--cfg-path', '/tmp/tmp7jb4qwtk']
[2024-11-11T21:10:22.528+0000] {standard_task_runner.py:91} INFO - Job 191: Subtask train_stock_model__1
[2024-11-11T21:10:22.579+0000] {task_command.py:426} INFO - Running <TaskInstance: two_stocks_DAG.train_stock_model__1 scheduled__2024-11-10T03:50:00+00:00 [running]> on host 889c1536fdc4
[2024-11-11T21:10:22.665+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='two_stocks_DAG' AIRFLOW_CTX_TASK_ID='train_stock_model__1' AIRFLOW_CTX_EXECUTION_DATE='2024-11-10T03:50:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-11-10T03:50:00+00:00'
[2024-11-11T21:10:22.666+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-11T21:10:22.677+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-11-11T21:10:22.678+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.0, Python Version: 3.12.3, Platform: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2024-11-11T21:10:22.679+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-11-11T21:10:23.393+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-11-11T21:10:23.562+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-11-11T21:10:23.986+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-11-11T21:10:47.357+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-11-11T21:10:48.676+0000] {logging_mixin.py:188} INFO - -20001 (P0001): 01b84eb6-0004-2b34-0000-000258f7d409: Uncaught exception of type 'INVALID_MODEL_EXCEPTION' on line 162 at position 8 : Invalid Model Object. Please contact Snowflake Support team to resolve this issue.
[2024-11-11T21:10:48.676+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-11T21:10:48.677+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/two_stocks.py", line 109, in train_stock_model
    cur.execute(f"CALL {forecast_function_name}!SHOW_EVALUATION_METRICS();")
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: -20001 (P0001): 01b84eb6-0004-2b34-0000-000258f7d409: Uncaught exception of type 'INVALID_MODEL_EXCEPTION' on line 162 at position 8 : Invalid Model Object. Please contact Snowflake Support team to resolve this issue.
[2024-11-11T21:10:48.686+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=two_stocks_DAG, task_id=train_stock_model__1, run_id=scheduled__2024-11-10T03:50:00+00:00, execution_date=20241110T035000, start_date=20241111T211022, end_date=20241111T211048
[2024-11-11T21:10:48.699+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 191 for task train_stock_model__1 (-20001 (P0001): 01b84eb6-0004-2b34-0000-000258f7d409: Uncaught exception of type 'INVALID_MODEL_EXCEPTION' on line 162 at position 8 : Invalid Model Object. Please contact Snowflake Support team to resolve this issue.; 488)
[2024-11-11T21:10:48.710+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-11-11T21:10:48.724+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-11-11T21:10:48.726+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
