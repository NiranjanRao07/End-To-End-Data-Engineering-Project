[2024-11-11T04:01:19.387+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-11T04:01:19.443+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: two_stocks_DAG.predict_stock__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T04:01:19.456+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: two_stocks_DAG.predict_stock__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T04:01:19.456+0000] {taskinstance.py:2306} INFO - Starting attempt 2 of 3
[2024-11-11T04:01:19.478+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): predict_stock__1> on 2024-11-10 03:50:00+00:00
[2024-11-11T04:01:19.492+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=1192) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-11-11T04:01:19.491+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'two_stocks_DAG', 'predict_stock__1', 'scheduled__2024-11-10T03:50:00+00:00', '--job-id', '122', '--raw', '--subdir', 'DAGS_FOLDER/two_stocks.py', '--cfg-path', '/tmp/tmpjj9wdj4n']
[2024-11-11T04:01:19.494+0000] {standard_task_runner.py:63} INFO - Started process 1222 to run task
[2024-11-11T04:01:19.494+0000] {standard_task_runner.py:91} INFO - Job 122: Subtask predict_stock__1
[2024-11-11T04:01:19.574+0000] {task_command.py:426} INFO - Running <TaskInstance: two_stocks_DAG.predict_stock__1 scheduled__2024-11-10T03:50:00+00:00 [running]> on host e77131eeb98c
[2024-11-11T04:01:19.706+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='two_stocks_DAG' AIRFLOW_CTX_TASK_ID='predict_stock__1' AIRFLOW_CTX_EXECUTION_DATE='2024-11-10T03:50:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-11-10T03:50:00+00:00'
[2024-11-11T04:01:19.708+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-11T04:01:19.719+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-11-11T04:01:19.721+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.0, Python Version: 3.12.3, Platform: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2024-11-11T04:01:19.723+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-11-11T04:01:20.092+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-11T04:01:20.093+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/two_stocks.py", line 118, in predict_stock
    cur = return_snowflake_conn()
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/two_stocks.py", line 13, in return_snowflake_conn
    conn = hook.get_conn()
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 287, in get_conn
    conn = connector.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/__init__.py", line 55, in Connect
    return SnowflakeConnection(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 442, in __init__
    self.connect(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 745, in connect
    self.__open_connection()
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1073, in __open_connection
    self.authenticate_with_retry(self.auth_class)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1345, in authenticate_with_retry
    self._authenticate(auth_instance)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1373, in _authenticate
    auth.authenticate(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/auth/_auth.py", line 250, in authenticate
    ret = self._rest._post_request(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 734, in _post_request
    ret = self.fetch(
          ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 843, in fetch
    ret = self._request_exec_wrapper(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 979, in _request_exec_wrapper
    raise e
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 884, in _request_exec_wrapper
    return_object = self._request_exec(
                    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 1193, in _request_exec
    raise err
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 1135, in _request_exec
    raise_failed_request_error(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 238, in raise_failed_request_error
    Error.errorhandler_wrapper(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 348, in hand_to_other_handler
    connection.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.InterfaceError: 250003 (08001): None: 404 Not Found: post https://azb69635.snowflakecomputing.com:443/session/v1/login-request?request_id=91920a95-ab04-438a-8f33-a21c5e6b3530&databaseName=DEV&schemaName=&warehouse=COMPUTE_WH&roleName=&request_guid=9a85c437-7f00-404b-89a5-c2e4369306f1
[2024-11-11T04:01:20.107+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=two_stocks_DAG, task_id=predict_stock__1, run_id=scheduled__2024-11-10T03:50:00+00:00, execution_date=20241110T035000, start_date=20241111T040119, end_date=20241111T040120
[2024-11-11T04:01:20.130+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 122 for task predict_stock__1 (250003 (08001): None: 404 Not Found: post https://azb69635.snowflakecomputing.com:443/session/v1/login-request?request_id=91920a95-ab04-438a-8f33-a21c5e6b3530&databaseName=DEV&schemaName=&warehouse=COMPUTE_WH&roleName=&request_guid=9a85c437-7f00-404b-89a5-c2e4369306f1; 1222)
[2024-11-11T04:01:20.153+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-11-11T04:01:20.166+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-11-11T21:15:25.627+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-11T21:15:25.652+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: two_stocks_DAG.predict_stock__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T21:15:25.660+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: two_stocks_DAG.predict_stock__1 scheduled__2024-11-10T03:50:00+00:00 [queued]>
[2024-11-11T21:15:25.660+0000] {taskinstance.py:2306} INFO - Starting attempt 2 of 3
[2024-11-11T21:15:25.673+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): predict_stock__1> on 2024-11-10 03:50:00+00:00
[2024-11-11T21:15:25.679+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=573) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-11-11T21:15:25.681+0000] {standard_task_runner.py:63} INFO - Started process 576 to run task
[2024-11-11T21:15:25.681+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'two_stocks_DAG', 'predict_stock__1', 'scheduled__2024-11-10T03:50:00+00:00', '--job-id', '198', '--raw', '--subdir', 'DAGS_FOLDER/two_stocks.py', '--cfg-path', '/tmp/tmpn9xnrgbx']
[2024-11-11T21:15:25.682+0000] {standard_task_runner.py:91} INFO - Job 198: Subtask predict_stock__1
[2024-11-11T21:15:25.732+0000] {task_command.py:426} INFO - Running <TaskInstance: two_stocks_DAG.predict_stock__1 scheduled__2024-11-10T03:50:00+00:00 [running]> on host 889c1536fdc4
[2024-11-11T21:15:25.814+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='two_stocks_DAG' AIRFLOW_CTX_TASK_ID='predict_stock__1' AIRFLOW_CTX_EXECUTION_DATE='2024-11-10T03:50:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-11-10T03:50:00+00:00'
[2024-11-11T21:15:25.815+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-11T21:15:25.827+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-11-11T21:15:25.828+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.0, Python Version: 3.12.3, Platform: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2024-11-11T21:15:25.829+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-11-11T21:15:27.921+0000] {logging_mixin.py:188} INFO - 210012 (P0001): 01b84ebb-0004-26b4-0000-000258f73935: [MLUserError] Invalid Model Object. Please contact Snowflake Support team to resolve this issue.
[2024-11-11T21:15:27.921+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-11T21:15:27.922+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/two_stocks.py", line 142, in predict_stock
    cur.execute(make_prediction_sql)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 210012 (P0001): 01b84ebb-0004-26b4-0000-000258f73935: [MLUserError] Invalid Model Object. Please contact Snowflake Support team to resolve this issue.
[2024-11-11T21:15:27.930+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=two_stocks_DAG, task_id=predict_stock__1, run_id=scheduled__2024-11-10T03:50:00+00:00, execution_date=20241110T035000, start_date=20241111T211525, end_date=20241111T211527
[2024-11-11T21:15:27.944+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 198 for task predict_stock__1 (210012 (P0001): 01b84ebb-0004-26b4-0000-000258f73935: [MLUserError] Invalid Model Object. Please contact Snowflake Support team to resolve this issue.; 576)
[2024-11-11T21:15:27.984+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-11-11T21:15:28.002+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-11-11T21:15:28.004+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
